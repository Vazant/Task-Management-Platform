<!--
Sources:
- Redmine Logging Best Practices: https://www.redmine.org/projects/redmine/wiki/RedmineLogging
- Daily Standup and Logging: https://www.atlassian.com/agile/scrum/standups
- Project Management Logging: https://www.pmi.org/learning/library/project-logging-best-practices-12345
- Technical Decision Records: https://adr.github.io/
- Architecture Decision Records: https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions
Last Updated: 2024-12-19
Maintainer: Project Management Team
-->

# Daily Logging Best Practices

## Назначение и область применения

Это правило обеспечивает создание структурированных, информативных ежедневных логов для отслеживания прогресса разработки, принятых решений и архитектурных изменений в проекте.

## Когда применять

- При ведении ежедневных логов разработки
- При документировании архитектурных решений
- При отслеживании прогресса проекта
- При ведении логов в Redmine или других системах управления проектами
- При создании технических решений и их обоснований

## Структура ежедневного лога

### ✅ DO: Полная структура лога
```markdown
**(ДД.ММ.ГГ)**

# [Тип работы]: [Краткое описание]

**Контекст**  
* Текущее состояние проекта или системы
* Ключевые технологии и архитектура
* Ограничения и зависимости

**Проблемы/Задачи**  
* Конкретные проблемы, которые решаем
* Технические ограничения
* Бизнес-требования

**Рассмотренные варианты**  
* [Вариант 1](ссылка)
  * Плюсы: преимущества решения
  * Минусы: недостатки и риски
  * Не выбрали потому что: обоснование отказа
  * Ссылки: [название](url), [название](url)
* [Вариант 2](ссылка)
  * Плюсы: преимущества решения
  * Минусы: недостатки и риски
  * Не выбрали потому что: обоснование отказа
  * Ссылки: [название](url), [название](url)

**Выбор**  
* Принятое решение с обоснованием
* Критерии выбора
* Ожидаемые результаты

**Почему [выбранное решение]**  
* Технические преимущества
* Бизнес-выгоды
* Соответствие архитектурным принципам

**Как будем реализовывать**  
* Пошаговый план внедрения
* Критические точки
* Риски и митигация

**Следующие шаги**  
* Конкретные действия на ближайшее время
* Ответственные
* Дедлайны

**Ожидаемый результат**  
* Измеримые результаты
* KPI и метрики
* Долгосрочные эффекты

**Дополнительные заметки**  
* Связанные задачи: #123, #124
* Зависимости от других команд
* Важные детали реализации
```

### ✅ DO: Типы логов

#### Архитектурные решения
```markdown
**(19.12.24)**

# Архитектурное решение: внедрение Event Sourcing

**Контекст**  
* Текущая система использует CRUD операции для аудита
* Нужна полная история изменений для compliance
* Высокие требования к производительности чтения

**Проблемы текущей архитектуры**  
* Невозможно восстановить состояние на произвольный момент
* Аудит только через логи, которые могут быть потеряны
* Сложно анализировать паттерны изменений

**Рассмотренные варианты**  
* [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
  * Плюсы: полная история, возможность replay, audit trail
  * Минусы: сложность, eventual consistency, storage overhead
  * Выбрали потому что: соответствует требованиям compliance
* [CQRS](https://martinfowler.com/bliki/CQRS.html)
  * Плюсы: разделение read/write моделей, оптимизация
  * Минусы: дополнительная сложность, eventual consistency
  * Не выбрали как основную потому что: пока не нужна оптимизация чтения
* [Change Data Capture](https://debezium.io/documentation/reference/stable/connectors/postgresql.html)
  * Плюсы: автоматическое отслеживание изменений
  * Минусы: привязка к БД, ограниченная гибкость
  * Не выбрали потому что: нужен контроль над событиями

**Выбор**  
* Event Sourcing для критичных доменов (User, Task, Project)
* Hybrid подход: события + снимки состояния
* Использование Apache Kafka для event store

**Почему Event Sourcing**  
* Соответствует требованиям аудита
* Позволяет анализировать паттерны использования
* Обеспечивает возможность восстановления состояния
* Подготавливает к CQRS в будущем

**Как будем реализовывать**  
* Начать с User Service как proof of concept
* Создать базовые event classes и handlers
* Настроить Kafka для event streaming
* Постепенно мигрировать другие сервисы

**Следующие шаги**  
* Создать ветку feature/event-sourcing
* Реализовать базовые события для User domain
* Настроить Kafka infrastructure
* Написать тесты для event handlers

**Ожидаемый результат**  
* Полный audit trail для всех изменений
* Возможность восстановления состояния
* Аналитика использования системы
* Подготовка к advanced patterns (CQRS, Saga)
```

#### Технические решения
```markdown
**(18.12.24)**

# Техническое решение: выбор ORM для микросервисов

**Контекст**  
* Переход на микросервисную архитектуру
* Нужна производительность и гибкость
* Команда знакома с JPA/Hibernate

**Проблемы текущего подхода**  
* Hibernate слишком тяжелый для микросервисов
* N+1 проблемы в сложных запросах
* Сложность настройки для разных БД

**Рассмотренные варианты**  
* [JPA/Hibernate](https://hibernate.org/orm/)
  * Плюсы: знакомство команды, богатая функциональность
  * Минусы: overhead, сложность, N+1 проблемы
  * Не выбрали потому что: не подходит для микросервисов
* [MyBatis](https://mybatis.org/mybatis-3/)
  * Плюсы: контроль SQL, производительность, простота
  * Минусы: больше boilerplate кода
  * Выбрали потому что: баланс производительности и контроля
* [JOOQ](https://www.jooq.org/)
  * Плюсы: type-safe SQL, производительность
  * Минусы: learning curve, vendor lock-in
  * Не выбрали потому что: слишком много изменений в коде
* [Spring Data JDBC](https://spring.io/projects/spring-data-jdbc)
  * Плюсы: простота, производительность, Spring integration
  * Минусы: ограниченная функциональность
  * Не выбрали потому что: недостаточно гибкости

**Выбор**  
* MyBatis для сложных запросов и производительности
* Spring Data JPA для простых CRUD операций
* Hybrid подход в зависимости от требований сервиса

**Почему MyBatis**  
* Полный контроль над SQL запросами
* Высокая производительность
* Простота отладки и оптимизации
* Хорошая интеграция с Spring Boot

**Как будем реализовывать**  
* Создать общие MyBatis конфигурации
* Настроить connection pooling
* Создать базовые мапперы и утилиты
* Постепенно мигрировать существующие репозитории

**Следующие шаги**  
* Настроить MyBatis в User Service
* Создать базовые мапперы для User entity
* Написать тесты для мапперов
* Документировать best practices

**Ожидаемый результат**  
* Улучшение производительности запросов на 30-50%
* Упрощение отладки SQL
* Больше контроля над оптимизацией
* Подготовка к масштабированию
```

#### Дневные задачи
```markdown
**(17.12.24)**

# Дневная работа: настройка мониторинга микросервисов

**Контекст**  
* Запущены первые микросервисы (User, Task)
* Нужен мониторинг производительности и ошибок
* Команда DevOps готова к настройке инфраструктуры

**Задачи дня**  
* Настроить Prometheus для сбора метрик
* Интегрировать Micrometer в Spring Boot приложения
* Создать Grafana дашборды
* Настроить алерты для критичных метрик

**Выполненные работы**  
* ✅ Добавлен Micrometer в pom.xml всех сервисов
* ✅ Настроены custom metrics для бизнес-логики
* ✅ Создан Prometheus configuration
* ✅ Настроены базовые Grafana дашборды
* 🔄 В процессе: настройка алертов

**Проблемы и решения**  
* Проблема: метрики не отображались в Grafana
* Решение: исправлена конфигурация Prometheus scrape config
* Проблема: высокое потребление памяти
* Решение: оптимизированы JVM параметры

**Следующие шаги**  
* Завершить настройку алертов
* Добавить distributed tracing с Jaeger
* Создать runbooks для операционной команды
* Настроить log aggregation

**Результат дня**  
* Мониторинг работает для всех сервисов
* Дашборды показывают ключевые метрики
* Команда может отслеживать производительность
* Готовность к production deployment

**Время затрачено**  
* Настройка метрик: 2 часа
* Конфигурация Prometheus: 1 час
* Создание дашбордов: 3 часа
* Отладка проблем: 1 час
* **Итого: 7 часов**
```

## Redmine Integration

### ✅ DO: Интеграция с Redmine
```markdown
## Redmine Best Practices

### Создание задач
- **Трекер**: "Разработка", "Архитектура", "Исследование"
- **Приоритет**: "Высокий", "Нормальный", "Низкий"
- **Статус**: "Новая", "В работе", "Решена", "Закрыта"
- **Версия**: привязка к спринту или релизу

### Ведение времени
- **Затраченное время**: фиксация в часах
- **Комментарии**: краткое описание выполненной работы
- **Прогресс**: процент выполнения задачи

### Связывание задач
- **Связанные задачи**: #123, #124
- **Блокирующие**: задачи, которые мешают выполнению
- **Дублирующие**: похожие задачи
- **Следует за**: задачи, которые должны быть выполнены после

### Пример Redmine лога
```
Задача: #456 - Настройка мониторинга микросервисов
Статус: В работе
Прогресс: 75%
Время: 6 часов

Комментарий:
**(17.12.24)**

# Дневная работа: настройка мониторинга микросервисов

**Выполнено:**
* ✅ Настроен Prometheus
* ✅ Созданы базовые дашборды
* 🔄 В процессе: настройка алертов

**Следующие шаги:**
* Завершить алерты
* Добавить Jaeger tracing

**Связанные задачи:** #455, #457
```
```

## Шаблоны для разных типов работ

### ✅ DO: Шаблон для исследований
```markdown
**(ДД.ММ.ГГ)**

# Исследование: [тема исследования]

**Контекст**  
* Зачем нужно это исследование
* Какие ограничения есть сейчас
* Какие требования к решению

**Исследованные технологии/подходы**  
* [Технология 1](ссылка)
  * Описание: что это и как работает
  * Плюсы: преимущества
  * Минусы: недостатки
  * Применимость: подходит ли для нашего случая
* [Технология 2](ссылка)
  * Описание: что это и как работает
  * Плюсы: преимущества
  * Минусы: недостатки
  * Применимость: подходит ли для нашего случая

**Рекомендации**  
* Какую технологию выбрать и почему
* План внедрения
* Риски и митигация

**Следующие шаги**  
* Конкретные действия
* Временные рамки
* Ответственные

**Ресурсы**  
* Документация: [ссылки]
* Примеры: [ссылки]
* Сообщество: [ссылки]
```

### ✅ DO: Шаблон для рефакторинга
```markdown
**(ДД.ММ.ГГ)**

# Рефакторинг: [что рефакторим]

**Контекст**  
* Текущее состояние кода
* Проблемы, которые нужно решить
* Цели рефакторинга

**Проблемы текущего кода**  
* Технический долг
* Нарушения принципов SOLID
* Проблемы производительности
* Сложность тестирования

**План рефакторинга**  
* Этап 1: [описание]
* Этап 2: [описание]
* Этап 3: [описание]

**Выполненные изменения**  
* ✅ Что сделано
* 🔄 Что в процессе
* ❌ Что отложено

**Результаты**  
* Улучшения производительности
* Упрощение кода
* Улучшение тестируемости
* Метрики: покрытие тестами, сложность кода

**Следующие шаги**  
* Продолжение рефакторинга
* Мониторинг результатов
* Документирование изменений
```

## Проверка соответствия

### Команды для проверки

```bash
# Проверка структуры лога
grep -E "^\*\*\([0-9]{2}\.[0-9]{2}\.[0-9]{2}\)\*\*" daily-log.md

# Проверка наличия обязательных секций
grep -E "^\*\*Контекст\*\*|^\*\*Проблемы|^\*\*Выбор\*\*|^\*\*Следующие шаги\*\*" daily-log.md

# Проверка ссылок
grep -o '\[.*\](http[^)]*)' daily-log.md | wc -l

# Проверка временных затрат
grep -E "Время|часов|минут" daily-log.md
```

### Чеклист ежедневного лога

#### ✅ Обязательные элементы
- [ ] Дата в формате **(ДД.ММ.ГГ)**
- [ ] Заголовок с типом работы
- [ ] Секция "Контекст" с текущим состоянием
- [ ] Описание проблем или задач
- [ ] Рассмотренные варианты с ссылками
- [ ] Обоснование выбора
- [ ] План реализации
- [ ] Следующие шаги
- [ ] Ожидаемые результаты
- [ ] Временные затраты

#### ✅ Рекомендуемые элементы
- [ ] Ссылки на документацию и ресурсы
- [ ] Связанные задачи (#123, #124)
- [ ] Риски и митигация
- [ ] Метрики и KPI
- [ ] Скриншоты или диаграммы
- [ ] Комментарии команды
- [ ] Зависимости от других задач
- [ ] Альтернативные решения
- [ ] Уроки learned
- [ ] Планы на следующий день

#### ❌ Что избегать
- [ ] Слишком краткие описания
- [ ] Отсутствие контекста
- [ ] Неработающие ссылки
- [ ] Неточные временные оценки
- [ ] Отсутствие обоснования решений
- [ ] Неструктурированная информация
- [ ] Дублирование информации
- [ ] Отсутствие следующих шагов
- [ ] Нереалистичные ожидания
- [ ] Технический жаргон без объяснений

## Примеры использования

### Создание лога для архитектурного решения
```markdown
**(19.12.24)**

# Архитектурное решение: выбор базы данных для микросервисов

**Контекст**  
* Переход на микросервисную архитектуру
* Нужна производительность и масштабируемость
* Требования к ACID транзакциям

**Проблемы текущего подхода**  
* PostgreSQL не справляется с нагрузкой
* Сложность горизонтального масштабирования
* Высокие требования к consistency

**Рассмотренные варианты**  
* [PostgreSQL](https://www.postgresql.org/)
  * Плюсы: ACID, богатая функциональность, знакомство команды
  * Минусы: сложность масштабирования, производительность
  * Не выбрали потому что: не подходит для высокой нагрузки
* [MongoDB](https://www.mongodb.com/)
  * Плюсы: горизонтальное масштабирование, гибкая схема
  * Минусы: eventual consistency, сложность транзакций
  * Не выбрали потому что: нужны ACID транзакции
* [CockroachDB](https://www.cockroachlabs.com/)
  * Плюсы: ACID, горизонтальное масштабирование, совместимость с PostgreSQL
  * Минусы: новая технология, learning curve
  * Выбрали потому что: решает все наши требования

**Выбор**  
* CockroachDB для критичных сервисов
* PostgreSQL для сервисов с простыми требованиями
* Redis для кэширования

**Почему CockroachDB**  
* ACID транзакции на уровне распределенной системы
* Автоматическое горизонтальное масштабирование
* Совместимость с PostgreSQL (легкая миграция)
* Высокая доступность и отказоустойчивость

**Как будем реализовывать**  
* Начать с User Service как proof of concept
* Настроить CockroachDB cluster
* Мигрировать схему и данные
* Постепенно переносить другие сервисы

**Следующие шаги**  
* Создать ветку feature/cockroachdb-migration
* Настроить CockroachDB cluster
* Создать миграционные скрипты
* Написать тесты для новой БД

**Ожидаемый результат**  
* Улучшение производительности на 40-60%
* Возможность горизонтального масштабирования
* Повышение доступности системы
* Упрощение операционных задач

**Связанные задачи:** #789, #790
```

### Создание лога для дневной работы
```markdown
**(18.12.24)**

# Дневная работа: оптимизация производительности API

**Контекст**  
* API медленно отвечает на сложные запросы
* Пользователи жалуются на таймауты
* Нужно улучшить производительность без breaking changes

**Задачи дня**  
* Проанализировать медленные запросы
* Оптимизировать SQL запросы
* Добавить кэширование
* Настроить мониторинг производительности

**Выполненные работы**  
* ✅ Проанализированы медленные запросы через EXPLAIN ANALYZE
* ✅ Оптимизированы 3 критичных SQL запроса
* ✅ Добавлено кэширование для часто запрашиваемых данных
* ✅ Настроен мониторинг времени ответа API
* 🔄 В процессе: настройка алертов

**Проблемы и решения**  
* Проблема: N+1 запросы в User-Task связях
* Решение: добавлен JOIN FETCH в JPA запросы
* Проблема: отсутствие индексов на часто используемых полях
* Решение: созданы составные индексы
* Проблема: кэш не инвалидировался при изменениях
* Решение: настроена TTL и manual invalidation

**Метрики улучшений**  
* Время ответа API: с 2.5s до 0.8s (-68%)
* Количество SQL запросов: с 15 до 3 (-80%)
* Использование CPU: с 85% до 45% (-47%)
* Покрытие кэшем: 60% запросов

**Следующие шаги**  
* Завершить настройку алертов
* Добавить database connection pooling
* Оптимизировать оставшиеся медленные запросы
* Написать performance тесты

**Результат дня**  
* Значительное улучшение производительности
* Пользователи больше не жалуются на таймауты
* Система готова к увеличению нагрузки
* Создана основа для дальнейших оптимизаций

**Время затрачено**  
* Анализ производительности: 2 часа
* Оптимизация SQL: 3 часа
* Настройка кэширования: 2 часа
* Мониторинг: 1 час
* **Итого: 8 часов**

**Связанные задачи:** #456, #457
```

## Автоматизация

### Pre-commit hooks
```bash
#!/bin/sh
# .git/hooks/pre-commit

echo "Checking daily log format..."

# Проверка наличия даты
if ! grep -qE "^\*\*\([0-9]{2}\.[0-9]{2}\.[0-9]{2}\)\*\*" daily-log.md; then
    echo "ERROR: Date format not found in daily log"
    exit 1
fi

# Проверка обязательных секций
required_sections=("Контекст" "Следующие шаги")
for section in "${required_sections[@]}"; do
    if ! grep -qE "^\*\*${section}\*\*" daily-log.md; then
        echo "ERROR: Required section '${section}' not found"
        exit 1
    fi
done

echo "Daily log format check passed!"
```

### CI/CD проверки
```yaml
# .github/workflows/daily-log-check.yml
name: Daily Log Check

on:
  push:
    paths:
      - 'daily-logs/*.md'

jobs:
  log-check:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Check log format
      run: |
        for log_file in daily-logs/*.md; do
          echo "Checking $log_file"
          
          # Check date format
          if ! grep -qE "^\*\*\([0-9]{2}\.[0-9]{2}\.[0-9]{2}\)\*\*" "$log_file"; then
            echo "ERROR: Date format not found in $log_file"
            exit 1
          fi
          
          # Check required sections
          required_sections=("Контекст" "Следующие шаги")
          for section in "${required_sections[@]}"; do
            if ! grep -qE "^\*\*${section}\*\*" "$log_file"; then
              echo "ERROR: Required section '${section}' not found in $log_file"
              exit 1
            fi
          done
        done
    
    - name: Check links
      uses: gaurav-nelson/github-action-markdown-link-check@v1
      with:
        files: 'daily-logs/*.md'
        use-quiet-mode: 'yes'
```

## Ссылки

- [Redmine Logging Best Practices](https://www.redmine.org/projects/redmine/wiki/RedmineLogging)
- [Daily Standup and Logging](https://www.atlassian.com/agile/scrum/standups)
- [Project Management Logging](https://www.pmi.org/learning/library/project-logging-best-practices-12345)
- [Technical Decision Records](https://adr.github.io/)
- [Architecture Decision Records](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions)
- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
- [CQRS](https://martinfowler.com/bliki/CQRS.html)
- [Hexagonal Architecture](https://alistair.cockburn.us/hexagonal-architecture/)
- [Strangler Fig Pattern](https://martinfowler.com/bliki/StranglerFigApplication.html)