<!--
Sources:
- Redmine Logging Best Practices: https://www.redmine.org/projects/redmine/wiki/RedmineLogging
- Daily Standup and Logging: https://www.atlassian.com/agile/scrum/standups
- Project Management Logging: https://www.pmi.org/learning/library/project-logging-best-practices-12345
- Technical Decision Records: https://adr.github.io/
- Architecture Decision Records: https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions
Last Updated: 2024-12-19
Maintainer: Project Management Team
-->

# Daily Logging Best Practices

## Назначение и область применения

Это правило обеспечивает создание структурированных, информативных ежедневных логов для отслеживания прогресса разработки, принятых решений и архитектурных изменений в проекте.

## Когда применять

- При ведении ежедневных логов разработки
- При документировании архитектурных решений
- При отслеживании прогресса проекта
- При ведении логов в Redmine или других системах управления проектами
- При создании технических решений и их обоснований

## Структура ежедневного лога

### ✅ DO: Сохранение логов
- Все ежедневные логи сохраняются в папку `daily-logs/`
- Формат файла: `YYYY-MM-DD-[тип-работы].md`
- Примеры: `2024-12-19-microservices-infrastructure.md`, `2024-12-19-daily-tasks.md`
- Папка `daily-logs/` добавлена в `.gitignore` - логи НЕ коммитятся в Git
- Логи предназначены только для личного использования и отслеживания прогресса

### ✅ DO: Принципы краткости
- Логи должны быть краткими и по существу
- Максимум 1-2 страницы на день
- Группируйте похожие задачи в один пункт
- Используйте краткие формулировки
- Избегайте избыточных деталей
- Фокусируйтесь на ключевых результатах и решениях

### ✅ DO: Полная структура лога
```markdown
**(ДД.ММ.ГГ)**

# [Тип работы]: [Краткое описание]

**Контекст**  
- Текущее состояние проекта или системы
- Ключевые технологии и архитектура
- Ограничения и зависимости

**Проблемы/Задачи**  
- Конкретные проблемы, которые решаем
- Технические ограничения
- Бизнес-требования

**Рассмотренные варианты**  
- [Вариант 1](ссылка)
  - Плюсы: преимущества решения
  - Минусы: недостатки и риски
  - Не выбрали потому что: обоснование отказа
  - Ссылки: [название](url), [название](url)
- [Вариант 2](ссылка)
  - Плюсы: преимущества решения
  - Минусы: недостатки и риски
  - Не выбрали потому что: обоснование отказа
  - Ссылки: [название](url), [название](url)

**Выбор**  
- Принятое решение с обоснованием
- Критерии выбора
- Ожидаемые результаты

**Почему [выбранное решение]**  
- Технические преимущества
- Бизнес-выгоды
- Соответствие архитектурным принципам

**Как будем реализовывать**  
- Пошаговый план внедрения
- Критические точки
- Риски и митигация

**Следующие шаги**  
- Конкретные действия на ближайшее время
- Ответственные
- Дедлайны

**Ожидаемый результат**  
- Измеримые результаты
- KPI и метрики
- Долгосрочные эффекты

**Дополнительные заметки**  
- Связанные задачи: #123, #124
- Зависимости от других команд
- Важные детали реализации
```

### ✅ DO: Типы логов

#### Архитектурные решения
```markdown
# Файл: daily-logs/2024-12-19-event-sourcing-architecture.md

**(19.12.24)**

# Архитектурное решение: внедрение Event Sourcing

**Контекст**  
- Текущая система использует CRUD операции для аудита
- Нужна полная история изменений для compliance
- Высокие требования к производительности чтения

**Проблемы текущей архитектуры**  
- Невозможно восстановить состояние на произвольный момент
- Аудит только через логи, которые могут быть потеряны
- Сложно анализировать паттерны изменений

**Рассмотренные варианты**  
- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
  - Плюсы: полная история, возможность replay, audit trail
  - Минусы: сложность, eventual consistency, storage overhead
  - Выбрали потому что: соответствует требованиям compliance
- [CQRS](https://martinfowler.com/bliki/CQRS.html)
  - Плюсы: разделение read/write моделей, оптимизация
  - Минусы: дополнительная сложность, eventual consistency
  - Не выбрали как основную потому что: пока не нужна оптимизация чтения
- [Change Data Capture](https://debezium.io/documentation/reference/stable/connectors/postgresql.html)
  - Плюсы: автоматическое отслеживание изменений
  - Минусы: привязка к БД, ограниченная гибкость
  - Не выбрали потому что: нужен контроль над событиями

**Выбор**  
- Event Sourcing для критичных доменов (User, Task, Project)
- Hybrid подход: события + снимки состояния
- Использование Apache Kafka для event store

**Почему Event Sourcing**  
- Соответствует требованиям аудита
- Позволяет анализировать паттерны использования
- Обеспечивает возможность восстановления состояния
- Подготавливает к CQRS в будущем

**Как будем реализовывать**  
- Начать с User Service как proof of concept
- Создать базовые event classes и handlers
- Настроить Kafka для event streaming
- Постепенно мигрировать другие сервисы

**Следующие шаги**  
- Создать ветку feature/event-sourcing
- Реализовать базовые события для User domain
- Настроить Kafka infrastructure
- Написать тесты для event handlers

**Ожидаемый результат**  
- Полный audit trail для всех изменений
- Возможность восстановления состояния
- Аналитика использования системы
- Подготовка к advanced patterns (CQRS, Saga)
```

#### Технические решения
```markdown
# Файл: daily-logs/2024-12-18-orm-selection.md

**(18.12.24)**

# Техническое решение: выбор ORM для микросервисов

**Контекст**  
- Переход на микросервисную архитектуру
- Нужна производительность и гибкость
- Команда знакома с JPA/Hibernate

**Проблемы текущего подхода**  
- Hibernate слишком тяжелый для микросервисов
- N+1 проблемы в сложных запросах
- Сложность настройки для разных БД

**Рассмотренные варианты**  
- [JPA/Hibernate](https://hibernate.org/orm/)
  - Плюсы: знакомство команды, богатая функциональность
  - Минусы: overhead, сложность, N+1 проблемы
  - Не выбрали потому что: не подходит для микросервисов
- [MyBatis](https://mybatis.org/mybatis-3/)
  - Плюсы: контроль SQL, производительность, простота
  - Минусы: больше boilerplate кода
  - Выбрали потому что: баланс производительности и контроля
- [JOOQ](https://www.jooq.org/)
  - Плюсы: type-safe SQL, производительность
  - Минусы: learning curve, vendor lock-in
  - Не выбрали потому что: слишком много изменений в коде
- [Spring Data JDBC](https://spring.io/projects/spring-data-jdbc)
  - Плюсы: простота, производительность, Spring integration
  - Минусы: ограниченная функциональность
  - Не выбрали потому что: недостаточно гибкости

**Выбор**  
- MyBatis для сложных запросов и производительности
- Spring Data JPA для простых CRUD операций
- Hybrid подход в зависимости от требований сервиса

**Почему MyBatis**  
- Полный контроль над SQL запросами
- Высокая производительность
- Простота отладки и оптимизации
- Хорошая интеграция с Spring Boot

**Как будем реализовывать**  
- Создать общие MyBatis конфигурации
- Настроить connection pooling
- Создать базовые мапперы и утилиты
- Постепенно мигрировать существующие репозитории

**Следующие шаги**  
- Настроить MyBatis в User Service
- Создать базовые мапперы для User entity
- Написать тесты для мапперов
- Документировать best practices

**Ожидаемый результат**  
- Улучшение производительности запросов на 30-50%
- Упрощение отладки SQL
- Больше контроля над оптимизацией
- Подготовка к масштабированию
```

#### Дневные задачи
```markdown
# Файл: daily-logs/2024-12-17-microservices-monitoring.md

**(17.12.24)**

# Дневная работа: настройка мониторинга микросервисов

**Контекст**  
- Запущены первые микросервисы (User, Task)
- Нужен мониторинг производительности и ошибок
- Команда DevOps готова к настройке инфраструктуры

**Задачи дня**  
- Настроить Prometheus для сбора метрик
- Интегрировать Micrometer в Spring Boot приложения
- Создать Grafana дашборды
- Настроить алерты для критичных метрик

**Выполненные работы**  
- Настроен мониторинг: Prometheus + Grafana + Micrometer
- Созданы дашборды и базовые алерты
- Исправлены проблемы с отображением метрик и потреблением памяти

**Следующие шаги**  
- Завершить настройку алертов
- Добавить Jaeger tracing и log aggregation

**Результат дня**  
- Мониторинг работает для всех сервисов
- Готовность к production deployment

**Время затрачено: 7 часов**
```

## Redmine Integration

### ✅ DO: Интеграция с Redmine
```markdown
## Redmine Best Practices

### Создание задач
- **Трекер**: "Разработка", "Архитектура", "Исследование"
- **Приоритет**: "Высокий", "Нормальный", "Низкий"
- **Статус**: "Новая", "В работе", "Решена", "Закрыта"
- **Версия**: привязка к спринту или релизу

### Ведение времени
- **Затраченное время**: фиксация в часах
- **Комментарии**: краткое описание выполненной работы
- **Прогресс**: процент выполнения задачи

### Связывание задач
- **Связанные задачи**: #123, #124
- **Блокирующие**: задачи, которые мешают выполнению
- **Дублирующие**: похожие задачи
- **Следует за**: задачи, которые должны быть выполнены после

### Пример Redmine лога
```
Задача: #456 - Настройка мониторинга микросервисов
Статус: В работе
Прогресс: 75%
Время: 6 часов

Комментарий:
**(17.12.24)**

# Дневная работа: настройка мониторинга микросервисов

**Выполнено:**
* ✅ Настроен Prometheus
* ✅ Созданы базовые дашборды
* 🔄 В процессе: настройка алертов

**Следующие шаги:**
* Завершить алерты
* Добавить Jaeger tracing

**Связанные задачи:** #455, #457
```
```

## Шаблоны для разных типов работ

### ✅ DO: Шаблон для исследований
```markdown
# Файл: daily-logs/YYYY-MM-DD-research-[тема].md

**(ДД.ММ.ГГ)**

# Исследование: [тема исследования]

**Контекст**  
- Зачем нужно это исследование
- Какие ограничения есть сейчас
- Какие требования к решению

**Исследованные технологии/подходы**  
- [Технология 1](ссылка)
  - Описание: что это и как работает
  - Плюсы: преимущества
  - Минусы: недостатки
  - Применимость: подходит ли для нашего случая
- [Технология 2](ссылка)
  - Описание: что это и как работает
  - Плюсы: преимущества
  - Минусы: недостатки
  - Применимость: подходит ли для нашего случая

**Рекомендации**  
- Какую технологию выбрать и почему
- План внедрения
- Риски и митигация

**Следующие шаги**  
- Конкретные действия
- Временные рамки
- Ответственные

**Ресурсы**  
- Документация: [ссылки]
- Примеры: [ссылки]
- Сообщество: [ссылки]
```

### ✅ DO: Шаблон для рефакторинга
```markdown
# Файл: daily-logs/YYYY-MM-DD-refactoring-[компонент].md

**(ДД.ММ.ГГ)**

# Рефакторинг: [что рефакторим]

**Контекст**  
- Текущее состояние кода
- Проблемы, которые нужно решить
- Цели рефакторинга

**Проблемы текущего кода**  
- Технический долг
- Нарушения принципов SOLID
- Проблемы производительности
- Сложность тестирования

**План рефакторинга**  
- Этап 1: [описание]
- Этап 2: [описание]
- Этап 3: [описание]

**Выполненные изменения**  
- Что сделано
- Что в процессе
- Что отложено

**Результаты**  
- Улучшения производительности
- Упрощение кода
- Улучшение тестируемости
- Метрики: покрытие тестами, сложность кода

**Следующие шаги**  
- Продолжение рефакторинга
- Мониторинг результатов
- Документирование изменений
```

## Проверка соответствия

### Команды для проверки

```bash
# Проверка структуры лога
grep -E "^\*\*\([0-9]{2}\.[0-9]{2}\.[0-9]{2}\)\*\*" daily-log.md

# Проверка наличия обязательных секций
grep -E "^\*\*Контекст\*\*|^\*\*Проблемы|^\*\*Выбор\*\*|^\*\*Следующие шаги\*\*" daily-log.md

# Проверка ссылок
grep -o '\[.*\](http[^)]*)' daily-log.md | wc -l

# Проверка временных затрат
grep -E "Время|часов|минут" daily-log.md
```

### Чеклист ежедневного лога

#### ✅ Обязательные элементы
- [ ] Дата в формате **(ДД.ММ.ГГ)**
- [ ] Заголовок с типом работы
- [ ] Секция "Контекст" с текущим состоянием
- [ ] Описание проблем или задач
- [ ] Рассмотренные варианты с ссылками
- [ ] Обоснование выбора
- [ ] План реализации
- [ ] Следующие шаги
- [ ] Ожидаемые результаты
- [ ] Временные затраты

#### ✅ Рекомендуемые элементы
- [ ] Ссылки на документацию и ресурсы
- [ ] Связанные задачи (#123, #124)
- [ ] Риски и митигация
- [ ] Метрики и KPI
- [ ] Скриншоты или диаграммы
- [ ] Комментарии команды
- [ ] Зависимости от других задач
- [ ] Альтернативные решения
- [ ] Уроки learned
- [ ] Планы на следующий день

#### ❌ Что избегать
- [ ] Слишком краткие описания
- [ ] Отсутствие контекста
- [ ] Неработающие ссылки
- [ ] Неточные временные оценки
- [ ] Отсутствие обоснования решений
- [ ] Неструктурированная информация
- [ ] Дублирование информации
- [ ] Отсутствие следующих шагов
- [ ] Нереалистичные ожидания
- [ ] Технический жаргон без объяснений

## Примеры использования

### Создание лога для архитектурного решения
```markdown
# Файл: daily-logs/2024-12-19-database-selection.md

**(19.12.24)**

# Архитектурное решение: выбор базы данных для микросервисов

**Контекст**  
- Переход на микросервисную архитектуру
- Нужна производительность и масштабируемость
- Требования к ACID транзакциям

**Проблемы текущего подхода**  
- PostgreSQL не справляется с нагрузкой
- Сложность горизонтального масштабирования
- Высокие требования к consistency

**Рассмотренные варианты**  
- [PostgreSQL](https://www.postgresql.org/)
  - Плюсы: ACID, богатая функциональность, знакомство команды
  - Минусы: сложность масштабирования, производительность
  - Не выбрали потому что: не подходит для высокой нагрузки
- [MongoDB](https://www.mongodb.com/)
  - Плюсы: горизонтальное масштабирование, гибкая схема
  - Минусы: eventual consistency, сложность транзакций
  - Не выбрали потому что: нужны ACID транзакции
- [CockroachDB](https://www.cockroachlabs.com/)
  - Плюсы: ACID, горизонтальное масштабирование, совместимость с PostgreSQL
  - Минусы: новая технология, learning curve
  - Выбрали потому что: решает все наши требования

**Выбор**  
- CockroachDB для критичных сервисов
- PostgreSQL для сервисов с простыми требованиями
- Redis для кэширования

**Почему CockroachDB**  
- ACID транзакции на уровне распределенной системы
- Автоматическое горизонтальное масштабирование
- Совместимость с PostgreSQL (легкая миграция)
- Высокая доступность и отказоустойчивость

**Как будем реализовывать**  
- Начать с User Service как proof of concept
- Настроить CockroachDB cluster
- Мигрировать схему и данные
- Постепенно переносить другие сервисы

**Следующие шаги**  
- Создать ветку feature/cockroachdb-migration
- Настроить CockroachDB cluster
- Создать миграционные скрипты
- Написать тесты для новой БД

**Ожидаемый результат**  
- Улучшение производительности на 40-60%
- Возможность горизонтального масштабирования
- Повышение доступности системы
- Упрощение операционных задач

**Связанные задачи:** #789, #790
```

### Создание лога для дневной работы
```markdown
# Файл: daily-logs/2024-12-18-api-performance-optimization.md

**(18.12.24)**

# Дневная работа: оптимизация производительности API

**Контекст**  
- API медленно отвечает на сложные запросы
- Пользователи жалуются на таймауты
- Нужно улучшить производительность без breaking changes

**Задачи дня**  
- Проанализировать медленные запросы
- Оптимизировать SQL запросы
- Добавить кэширование
- Настроить мониторинг производительности

**Выполненные работы**  
- Оптимизированы SQL запросы (устранены N+1 проблемы, добавлены индексы)
- Настроено кэширование с TTL и manual invalidation
- Добавлен мониторинг производительности API

**Метрики улучшений**  
- Время ответа: с 2.5s до 0.8s (-68%)
- SQL запросы: с 15 до 3 (-80%)
- CPU: с 85% до 45% (-47%)

**Следующие шаги**  
- Завершить алерты, добавить connection pooling, performance тесты

**Результат дня**  
- Значительное улучшение производительности, готовность к росту нагрузки

**Время затрачено: 8 часов**

**Связанные задачи:** #456, #457
```

## Автоматизация

### Pre-commit hooks
```bash
#!/bin/sh
# .git/hooks/pre-commit

echo "Checking daily log format..."

# Проверка наличия даты в файлах daily-logs/
if [ -d "daily-logs" ]; then
    for log_file in daily-logs/*.md; do
        if [ -f "$log_file" ]; then
            if ! grep -qE "^\*\*\([0-9]{2}\.[0-9]{2}\.[0-9]{2}\)\*\*" "$log_file"; then
                echo "ERROR: Date format not found in $log_file"
                exit 1
            fi
            
            # Проверка обязательных секций
            required_sections=("Контекст" "Следующие шаги")
            for section in "${required_sections[@]}"; do
                if ! grep -qE "^\*\*${section}\*\*" "$log_file"; then
                    echo "ERROR: Required section '${section}' not found in $log_file"
                    exit 1
                fi
            done
        fi
    done
fi

echo "Daily log format check passed!"
```

### CI/CD проверки
```yaml
# .github/workflows/daily-log-check.yml
name: Daily Log Check

on:
  push:
    paths:
      - 'daily-logs/*.md'

jobs:
  log-check:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Check log format
      run: |
        if [ -d "daily-logs" ]; then
          for log_file in daily-logs/*.md; do
            if [ -f "$log_file" ]; then
              echo "Checking $log_file"
              
              # Check date format
              if ! grep -qE "^\*\*\([0-9]{2}\.[0-9]{2}\.[0-9]{2}\)\*\*" "$log_file"; then
                echo "ERROR: Date format not found in $log_file"
                exit 1
              fi
              
              # Check required sections
              required_sections=("Контекст" "Следующие шаги")
              for section in "${required_sections[@]}"; do
                if ! grep -qE "^\*\*${section}\*\*" "$log_file"; then
                  echo "ERROR: Required section '${section}' not found in $log_file"
                  exit 1
                fi
              done
            fi
          done
        else
          echo "No daily-logs directory found, skipping check"
        fi
    
    - name: Check links
      if: contains(github.event.head_commit.modified, 'daily-logs/')
      uses: gaurav-nelson/github-action-markdown-link-check@v1
      with:
        files: 'daily-logs/*.md'
        use-quiet-mode: 'yes'
```

## Ссылки

- [Redmine Logging Best Practices](https://www.redmine.org/projects/redmine/wiki/RedmineLogging)
- [Daily Standup and Logging](https://www.atlassian.com/agile/scrum/standups)
- [Project Management Logging](https://www.pmi.org/learning/library/project-logging-best-practices-12345)
- [Technical Decision Records](https://adr.github.io/)
- [Architecture Decision Records](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions)
- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
- [CQRS](https://martinfowler.com/bliki/CQRS.html)
- [Hexagonal Architecture](https://alistair.cockburn.us/hexagonal-architecture/)
- [Strangler Fig Pattern](https://martinfowler.com/bliki/StranglerFigApplication.html)